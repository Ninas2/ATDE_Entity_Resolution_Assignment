{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec6ffa6",
   "metadata": {},
   "source": [
    "# Advanced Topics in Data Enginnering - Assignment 2\n",
    "\n",
    "## Entity-Relationship \n",
    "\n",
    "> Konstantinos Ninas, f2822108 <br />\n",
    "> MSc in Business Analytics <br />\n",
    "> Department of Management Science and Technology <br />\n",
    "> Athens University of Economics and Business <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26097bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c62f170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QD Inc</td>\n",
       "      <td>San Diego,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11578 Sorrento Valley Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS Argon, JG Hannoosh</td>\n",
       "      <td>Phil. Mag,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Initiation of crazes in polystyrene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GH Hansen, LL Wetterberg, H SjÃ¶strÃ¶m, O NorÃ©n</td>\n",
       "      <td>The Histochemical Journal,</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Immunogold labelling is a quantitative method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TM Hammett, P Harmon, W Rhodes</td>\n",
       "      <td>see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Burden of Infectious Disease Among Inmates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JR Cogdell</td>\n",
       "      <td>NEW DIRECTIONS FOR TEACHING AND LEARNING,</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>The Role of Faculty Advising in Science and En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WM Schmidt</td>\n",
       "      <td>to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The zero multiplicity of linear recurrence seq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RA Haats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>PREDICITVE VALIDITY OF KINDERGARTEN SCREENERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JR Norris, J Deisenhofer</td>\n",
       "      <td>San Diego: Academic,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Photosynthetic Reaction Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F Bennour</td>\n",
       "      <td>Res. Rep. CERIA, U. Paris,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F., Diene, AW, Ndiaye, Y. Hachage linÃ©aire Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I Borg, JC Lingoes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Multidimensional similarity structure analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "id                                                     \n",
       "1                                             QD Inc   \n",
       "2                              AS Argon, JG Hannoosh   \n",
       "3   GH Hansen, LL Wetterberg, H SjÃ¶strÃ¶m, O NorÃ©n   \n",
       "4                     TM Hammett, P Harmon, W Rhodes   \n",
       "5                                         JR Cogdell   \n",
       "6                                         WM Schmidt   \n",
       "7                                           RA Haats   \n",
       "8                           JR Norris, J Deisenhofer   \n",
       "9                                          F Bennour   \n",
       "10                                I Borg, JC Lingoes   \n",
       "\n",
       "                                        venue    year  \\\n",
       "id                                                      \n",
       "1                                  San Diego,     NaN   \n",
       "2                                  Phil. Mag,     NaN   \n",
       "3                  The Histochemical Journal,  1992.0   \n",
       "4                                         see     NaN   \n",
       "5   NEW DIRECTIONS FOR TEACHING AND LEARNING,  1995.0   \n",
       "6                                          to     NaN   \n",
       "7                                         NaN  2002.0   \n",
       "8                        San Diego: Academic,     NaN   \n",
       "9                  Res. Rep. CERIA, U. Paris,     NaN   \n",
       "10                                        NaN  1987.0   \n",
       "\n",
       "                                                title  \n",
       "id                                                     \n",
       "1                          11578 Sorrento Valley Road  \n",
       "2                 Initiation of crazes in polystyrene  \n",
       "3   Immunogold labelling is a quantitative method ...  \n",
       "4   The Burden of Infectious Disease Among Inmates...  \n",
       "5   The Role of Faculty Advising in Science and En...  \n",
       "6   The zero multiplicity of linear recurrence seq...  \n",
       "7   PREDICITVE VALIDITY OF KINDERGARTEN SCREENERS ...  \n",
       "8                  The Photosynthetic Reaction Center  \n",
       "9   F., Diene, AW, Ndiaye, Y. Hachage linÃ©aire Sc...  \n",
       "10     Multidimensional similarity structure analysis  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the csv file\n",
    "authors = pd.read_csv('ER-Data.csv', sep=';')\n",
    "#convert the column id to index\n",
    "authors = authors.set_index('id')\n",
    "authors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27019851",
   "metadata": {},
   "source": [
    "## Task A - Conduct Token Blocking on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f4c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qd inc</td>\n",
       "      <td>san diego,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11578 sorrento valley road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as argon, jg hannoosh</td>\n",
       "      <td>phil. mag,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>initiation of crazes in polystyrene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh hansen, ll wetterberg, h sjã¶strã¶m, o norã©n</td>\n",
       "      <td>the histochemical journal,</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>immunogold labelling is a quantitative method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm hammett, p harmon, w rhodes</td>\n",
       "      <td>see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the burden of infectious disease among inmates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jr cogdell</td>\n",
       "      <td>new directions for teaching and learning,</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>the role of faculty advising in science and en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "id                                                     \n",
       "1                                             qd inc   \n",
       "2                              as argon, jg hannoosh   \n",
       "3   gh hansen, ll wetterberg, h sjã¶strã¶m, o norã©n   \n",
       "4                     tm hammett, p harmon, w rhodes   \n",
       "5                                         jr cogdell   \n",
       "\n",
       "                                        venue    year  \\\n",
       "id                                                      \n",
       "1                                  san diego,     NaN   \n",
       "2                                  phil. mag,     NaN   \n",
       "3                  the histochemical journal,  1992.0   \n",
       "4                                         see     NaN   \n",
       "5   new directions for teaching and learning,  1995.0   \n",
       "\n",
       "                                                title  \n",
       "id                                                     \n",
       "1                          11578 sorrento valley road  \n",
       "2                 initiation of crazes in polystyrene  \n",
       "3   immunogold labelling is a quantitative method ...  \n",
       "4   the burden of infectious disease among inmates...  \n",
       "5   the role of faculty advising in science and en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first, we must convert all text columns to lowercase\n",
    "authors['authors'] = authors['authors'].str.lower()\n",
    "authors['venue'] = authors['venue'].str.lower()\n",
    "authors['title'] = authors['title'].str.lower()\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd4a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 1992., 1995., 2002., 1987., 1996., 1998., 1997., 1999.,\n",
       "       2001., 2000., 1993., 2003., 1994., 1990., 1989., 2004., 1984.,\n",
       "       1964., 1991., 1975., 1977., 1988., 1982., 2005., 1980., 1986.,\n",
       "       1971., 1976., 1967., 1985., 1983., 1974., 1979., 1981., 1978.,\n",
       "       1961., 2006., 1970., 1972., 1973., 1960., 1954., 1957., 1959.,\n",
       "       1880., 1968., 1969., 1950., 1951., 1966., 1963., 1949., 1965.,\n",
       "       1962., 1955., 1931., 1906., 1945., 1910., 1921., 1938., 1942.,\n",
       "       1884., 1907., 1947., 1911., 1956.,   11., 1928., 1930., 1948.,\n",
       "       1914., 1932., 1923., 1800., 1946., 1927., 1953., 1933.,   51.,\n",
       "       1937.,   20., 1903., 2730., 1915., 1895., 1952., 1806.,  921.,\n",
       "       1935., 1916., 1779., 1958., 1909., 1925., 1750., 1934., 1882.,\n",
       "       1784., 1922., 1808., 1851., 1870., 1881., 1920.,   41., 1901.,\n",
       "       1908., 1940., 1848., 1941., 1939., 1912., 1944., 1899.,   22.,\n",
       "       1850., 1897., 1924., 1913., 1890., 1793., 1919., 1929., 1751.,\n",
       "       1763., 1902.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we observe all the distinct values of the year column\n",
    "authors['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa65356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', '1992', '1995', '2002', '1987', '1996', '1998', '1997',\n",
       "       '1999', '2001', '2', '1993', '2003', '1994', '199', '1989', '2004',\n",
       "       '1984', '1964', '1991', '1975', '1977', '1988', '1982', '2005',\n",
       "       '198', '1986', '1971', '1976', '1967', '1985', '1983', '1974',\n",
       "       '1979', '1981', '1978', '1961', '2006', '197', '1972', '1973',\n",
       "       '196', '1954', '1957', '1959', '188', '1968', '1969', '195',\n",
       "       '1951', '1966', '1963', '1949', '1965', '1962', '1955', '1931',\n",
       "       '1906', '1945', '191', '1921', '1938', '1942', '1884', '1907',\n",
       "       '1947', '1911', '1956', '11', '1928', '193', '1948', '1914',\n",
       "       '1932', '1923', '18', '1946', '1927', '1953', '1933', '51', '1937',\n",
       "       '1903', '273', '1915', '1895', '1952', '1806', '921', '1935',\n",
       "       '1916', '1779', '1958', '1909', '1925', '175', '1934', '1882',\n",
       "       '1784', '1922', '1808', '1851', '187', '1881', '192', '41', '1901',\n",
       "       '1908', '194', '1848', '1941', '1939', '1912', '1944', '1899',\n",
       "       '22', '185', '1897', '1924', '1913', '189', '1793', '1919', '1929',\n",
       "       '1751', '1763', '1902'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix the format of the years\n",
    "authors['year'] = authors['year'].astype(str).str.strip(\".0\")\n",
    "authors['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51835864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1                                     qd inc\n",
       "2                       as argon jg hannoosh\n",
       "3    gh hansen ll wetterberg h sjstrm o norn\n",
       "4               tm hammett p harmon w rhodes\n",
       "5                                 jr cogdell\n",
       "Name: authors, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all characters that are not alphanumeric or underscore in authors column\n",
    "authors['authors'].replace(regex=True, inplace=True,to_replace=r'[^a-zA-Z ]+',value=\"\")\n",
    "authors['authors'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0967a171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1                                   san diego\n",
       "2                                    phil mag\n",
       "3                   the histochemical journal\n",
       "4                                         see\n",
       "5    new directions for teaching and learning\n",
       "Name: venue, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all characters that are not alphanumeric or underscore in venue column\n",
    "authors['venue'].replace(regex=True, inplace=True,to_replace=r'[^a-zA-Z ]+',value=\"\")\n",
    "authors['venue'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a09869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1                                 sorrento valley road\n",
       "2                  initiation of crazes in polystyrene\n",
       "3    immunogold labelling is a quantitative method ...\n",
       "4    the burden of infectious disease among inmates...\n",
       "5    the role of faculty advising in science and en...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all characters that are not alphanumeric or underscore in title column\n",
    "authors['title'].replace(regex=True, inplace=True,to_replace=r'[^a-zA-Z ]+',value=\"\")\n",
    "authors['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6230a970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qd': [{'id': 1}],\n",
       " 'san': [{'id': 1}],\n",
       " 'diego': [{'id': 1}],\n",
       " 'nan': [{'id': 1}],\n",
       " 'sorrento': [{'id': 1}],\n",
       " 'valley': [{'id': 1}],\n",
       " 'road': [{'id': 1}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "blocks = dict()\n",
    "entity = authors.loc[index,]\n",
    "for attribute in entity:\n",
    "    #we receive all tokens in the entity's attributes\n",
    "    all_tokens = str(attribute).split()\n",
    "    #we remove stop words, if they exist, such as to, from, too and more.\n",
    "    tokens_without_sw = [word for word in all_tokens if not word in stopwords.words()]\n",
    "    #we iterate through each token\n",
    "    for token in tokens_without_sw:\n",
    "        # if a key with the token exists, append the id of the author in the values\n",
    "        if token in blocks.keys():\n",
    "            blocks[token].append(dict(id=index))\n",
    "        # else create a new key and assign it the id of the author as value\n",
    "        else:\n",
    "            blocks[token] = [dict(id=index)] \n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f6a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dictionary\n",
    "blocks = dict()\n",
    "#create a function that will conduct the token blocking\n",
    "def createTokenBlocks(dataset):\n",
    "    index = 1\n",
    "    #a while-loop that will iterate through all record\n",
    "    while index < (len(dataset)+1):\n",
    "        entity = dataset.loc[index,]\n",
    "        #we take all of his attributes one by one\n",
    "        for attribute in entity:\n",
    "            #we receive all tokens in the entity's attributes\n",
    "            all_tokens = str(attribute).split()\n",
    "            #we remove stop words, if they exist, such as to, from, too and more.\n",
    "            tokens_without_sw = [word for word in all_tokens if not word in stopwords.words()]\n",
    "            #we iterate through each token\n",
    "            for token in tokens_without_sw:\n",
    "                # if a key with the token exists, append the id of the author in the values\n",
    "                if token in blocks.keys():\n",
    "                    blocks[token].append(dict(id=index))\n",
    "                # else create a new key and assign it the id of the author as value\n",
    "                else:\n",
    "                    blocks[token] = [dict(id=index)] \n",
    "            \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8974cd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bbbee22a6b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#apply the function in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcreateTokenBlocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#list(authors.keys())[1:10]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-a4cd712c611e>\u001b[0m in \u001b[0;36mcreateTokenBlocks\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#we remove stop words, if they exist, such as to, from, too and more.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtokens_without_sw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;31m#we iterate through each token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens_without_sw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-a4cd712c611e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#we remove stop words, if they exist, such as to, from, too and more.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtokens_without_sw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;31m#we iterate through each token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens_without_sw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     21\u001b[0m         return [\n\u001b[0;32m     22\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file or directory: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#apply the function in the dataset\n",
    "createTokenBlocks(authors)\n",
    "#list(authors.keys())[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we identified a null key in the dictionary, so we will remove it\n",
    "clean_tokens = {k: v for k, v in blocks.items() if k == k}\n",
    "#we also remove those with key 'nan'\n",
    "del clean_tokens['nan']\n",
    "pprint.pprint(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e329f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also remove all the key value pairs that only have one author\n",
    "#number of keys in the initial dictionary\n",
    "number_of_keys = len(clean_tokens.keys())\n",
    "\n",
    "#we create a dictionary that only contains tokens that have more than 1 authors\n",
    "clean_tokens = {k: v for k, v in clean_tokens.items() if len(v) > 1}\n",
    "#number of keys in the new dictionary\n",
    "cleaned_no_of_keys = len(blocks_cleaned.keys())\n",
    "print('The keys in the dictionary were reduced from {} to {}'.format(number_of_keys, cleaned_no_of_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021d449",
   "metadata": {},
   "source": [
    "## Task B - Calculate the number of comparisons needed to examine the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will find the number of all comparisons necessary to go thorugh all the records of authors\n",
    "def all_comparisons(dct):\n",
    "    #create a null dataframe\n",
    "#     edge_list = pd.DataFrame(columns=['id1','id2'])\n",
    "    total_comp = 0\n",
    "    for j in list(dct.keys()):\n",
    "        temp_sum = int((len(dct[j]) * (len(dct[j]) - 1))/2)\n",
    "        total_comp += temp_sum\n",
    "#             #find all combinations of 2 authors per observation\n",
    "#             temp = list(combinations(dct[j], 2))\n",
    "#             #insert the combinations in a temporary dataframe\n",
    "#             temp_df = pd.DataFrame(temp, columns=['id1','id2'])\n",
    "#             #append the temporary dataframe to the edge_list df\n",
    "#             edge_list = edge_list.append(temp_df, ignore_index = True)\n",
    "    \n",
    "    return(total_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b095b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function on the clean token blocks\n",
    "no_of_comp = all_comparisons(clean_tokens)\n",
    "print('{} comparisons are needed to examine the whole dataset.'.format(no_of_comp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bdb402",
   "metadata": {},
   "source": [
    "## Task C - Create a Meta Blocking Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08866a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768bfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e54a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
